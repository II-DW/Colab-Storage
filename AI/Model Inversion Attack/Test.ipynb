{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjf95AW24CPKc1CAmieKi2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"damcG1vJ7HhD","executionInfo":{"status":"ok","timestamp":1712331770954,"user_tz":-540,"elapsed":1611,"user":{"displayName":"이도원","userId":"03706024893243123448"}},"outputId":"5a637a70-a852-4744-96b7-bd8c27a110ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted prices: [211052.63157895 251710.52631579]\n"]}],"source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Sample data: housing features and prices\n","# Features: square footage, number of bedrooms, number of bathrooms\n","X = np.array([[1500, 3, 2],\n","              [2000, 4, 3],\n","              [1200, 2, 1],\n","              [1800, 3, 2]])\n","\n","# Corresponding housing prices\n","y = np.array([200000, 250000, 180000, 220000])\n","\n","# Train a linear regression model\n","model = LinearRegression()\n","model.fit(X, y)\n","\n","# Predict housing prices for new data\n","new_data = np.array([[1600, 3, 2],\n","                     [2200, 4, 2]])\n","predicted_prices = model.predict(new_data)\n","print(\"Predicted prices:\", predicted_prices)\n"]},{"cell_type":"code","source":["import numpy as np\n","from scipy.optimize import minimize\n","\n","# Trained linear regression model coefficients and intercept\n","coefficients = model.coef_\n","intercept = model.intercept_\n","\n","# Predicted housing prices from the model\n","predicted_prices = model.predict(X)\n","\n","# Define inversion attack objective function\n","def inversion_objective(features):\n","    return np.sum(np.square(model.predict(features.reshape(1, -1)) - predicted_prices))\n","\n","# Initialize starting features for optimization\n","initial_features = np.array([1500, 3, 2])  # Initial guess for square footage, bedrooms, bathrooms\n","\n","# Perform inversion attack using optimization\n","result = minimize(inversion_objective, initial_features, method='Powell')\n","\n","# Extract inferred features from optimization result\n","inferred_features = result.x\n","\n","print(\"Inferred features (square footage, bedrooms, bathrooms):\", inferred_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQ29V3s87JtR","executionInfo":{"status":"ok","timestamp":1712331774675,"user_tz":-540,"elapsed":317,"user":{"displayName":"이도원","userId":"03706024893243123448"}},"outputId":"7af0ba04-b7ea-4d28-f4c7-629ec1a2f3e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inferred features (square footage, bedrooms, bathrooms): [1625.00000251    3.            1.99999995]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from scipy.optimize import minimize\n","\n","# Trained linear regression model coefficients and intercept\n","coefficients = model.coef_\n","intercept = model.intercept_\n","\n","# Predicted housing prices from the model\n","predicted_prices = model.predict(X)\n","\n","# Define inversion attack objective function for multiple data points\n","def inversion_objective(features):\n","    return np.sum(np.square(model.predict(features.reshape(1, -1)) - predicted_prices))\n","\n","# Initialize starting features for optimization (for multiple data points)\n","initial_features = np.array([[1500, 3, 2], [2000, 4, 3], [1200, 2, 1], [1800, 3, 2]])  # Initial guesses for square footage, bedrooms, bathrooms for each data point\n","\n","# Perform inversion attack using optimization for each data point\n","inferred_features = np.zeros_like(initial_features)\n","for i, initial_feature in enumerate(initial_features):\n","    result = minimize(inversion_objective, initial_feature, method='Powell')\n","    inferred_features[i] = result.x\n","\n","print(\"Inferred features (square footage, bedrooms, bathrooms) for each data point:\")\n","print(inferred_features)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKcFstA87VYk","executionInfo":{"status":"ok","timestamp":1712332140750,"user_tz":-540,"elapsed":321,"user":{"displayName":"이도원","userId":"03706024893243123448"}},"outputId":"554c37c3-65bc-4fe1-bd5a-b3c62f17220f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inferred features (square footage, bedrooms, bathrooms) for each data point:\n","[[1625    3    1]\n"," [1420    3    2]\n"," [1829    1    0]\n"," [1624    2    1]]\n"]}]},{"cell_type":"code","source":["!pip install python-dp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSap3un1DrtN","executionInfo":{"status":"ok","timestamp":1712401175772,"user_tz":-540,"elapsed":8975,"user":{"displayName":"이도원","userId":"03706024893243123448"}},"outputId":"65707462-ca94-4687-9a9a-76a94cadf40d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-dp\n","  Downloading python_dp-1.1.4-cp310-cp310-manylinux1_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-dp\n","Successfully installed python-dp-1.1.4\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Q7EKMgyHDrRo"}},{"cell_type":"code","source":["from pydp.algorithms.laplacian import BoundedMean\n","from pydp.algorithms.laplacian import BoundedSum\n","\n","# Sample data (numeric values)\n","data = [10, 20, 30, 40, 50]\n","\n","# Define privacy parameters\n","epsilon = 1.0  # Privacy parameter\n","\n","# Apply Gaussian differential privacy mechanism for mean computation\n","dp_mean = BoundedMean(epsilon=epsilon, lower_bound=0, upper_bound=100)\n","noisy_mean = dp_mean.quick_result(data)\n","\n","# Apply Gaussian differential privacy mechanism for sum computation\n","dp_sum = BoundedSum(epsilon=epsilon, lower_bound=0, upper_bound=100)\n","noisy_sum = dp_sum.quick_result(data)\n","\n","print(\"Noisy mean:\", noisy_mean)\n","print(\"Noisy sum:\", noisy_sum)"],"metadata":{"id":"mEz3ywBt8ejN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712401208129,"user_tz":-540,"elapsed":430,"user":{"displayName":"이도원","userId":"03706024893243123448"}},"outputId":"cb5c7a83-278a-4ed5-8ac1-29a960e1b787"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Noisy mean: 43.0\n","Noisy sum: 156\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the face recovery algorithm function\n","def face_recovery_algorithm(target_embedding, black_box_model, loss_function, num_queries):\n","    # Step 1: Initialization\n","    X = np.zeros_like(target_embedding)\n","    G0 = np.zeros_like(target_embedding)\n","\n","    # Step 3: Loop through the number of queries\n","    for i in range(num_queries):\n","        # Step 4: Allocate image batch\n","        X_batch = np.zeros((batch_size, *target_embedding.shape))\n","\n","        # Step 5: Sample batch of random gaussians\n","        G_batch = np.random.randn(*X_batch.shape)\n","\n","        # Step 6: Generate modified images\n","        X_modified = X + G0 + G_batch\n","\n","        # Step 7: Get predictions for modified images\n","        y_0 = black_box_model.predict(X_modified)\n","\n","        # Step 8: Calculate loss and find index of minimum loss\n","        losses = [loss_function(target_embedding, y_pred) for y_pred in y_0]\n","        ind = np.argmin(losses)\n","\n","        # Step 9: Update X\n","        X += X_modified[ind]\n","\n","        # Step 10: Update G0\n","        G0 *= 0.99\n","\n","        # Step 11: Increment i\n","        i += batch_size\n","\n","    # Step 13: Final update\n","    X += G0\n","\n","    return X\n","\n","# Example usage\n","target_embedding = np.array(...)  # Your target face embedding\n","black_box_model = ...  # Your black-box model\n","loss_function = ...  # Your loss function\n","num_queries = 100\n","reconstructed_face = face_recovery_algorithm(target_embedding, black_box_model, loss_function, num_queries)\n"],"metadata":{"id":"trfD8lo0U2CW"},"execution_count":null,"outputs":[]}]}